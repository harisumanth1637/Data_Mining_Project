{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2b7ac22c-db19-4c62-bdd6-7fd07a5aaf22",
      "metadata": {
        "id": "2b7ac22c-db19-4c62-bdd6-7fd07a5aaf22"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import os\n",
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from urllib3.exceptions import InsecureRequestWarning\n",
        "from urllib3 import disable_warnings\n",
        "from urllib.parse import urlparse, urlunparse\n",
        "import urllib3\n",
        "import urllib.request\n",
        "import whois\n",
        "from datetime import datetime\n",
        "import ipaddress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7dc0c225-27b0-4486-a153-ed5d2ab7d7bf",
      "metadata": {
        "id": "7dc0c225-27b0-4486-a153-ed5d2ab7d7bf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# has_title\n",
        "def has_title(soup):\n",
        "    if soup.title is None:\n",
        "        return 0\n",
        "    if len(soup.title.text) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has_input\n",
        "def has_input(soup):\n",
        "    if len(soup.find_all(\"input\")):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has_button\n",
        "def has_button(soup):\n",
        "    if len(soup.find_all(\"button\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has_image\n",
        "def has_image(soup):\n",
        "    if len(soup.find_all(\"image\")) == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "\n",
        "# has_submit\n",
        "def has_submit(soup):\n",
        "    for button in soup.find_all(\"input\"):\n",
        "        if button.get(\"type\") == \"submit\":\n",
        "            return 1\n",
        "        else:\n",
        "            pass\n",
        "    return 0\n",
        "\n",
        "\n",
        "# has_link\n",
        "def has_link(soup):\n",
        "    if len(soup.find_all(\"link\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has_password\n",
        "def has_password(soup):\n",
        "    for input in soup.find_all(\"input\"):\n",
        "        if (input.get(\"type\") or input.get(\"name\") or input.get(\"id\")) == \"password\":\n",
        "            return 1\n",
        "        else:\n",
        "            pass\n",
        "    return 0\n",
        "\n",
        "\n",
        "# has_email_input\n",
        "def has_email_input(soup):\n",
        "    for input in soup.find_all(\"input\"):\n",
        "        if (input.get(\"type\") or input.get(\"id\") or input.get(\"name\")) == \"email\":\n",
        "            return 1\n",
        "        else:\n",
        "            pass\n",
        "    return 0\n",
        "\n",
        "\n",
        "# has_hidden_element\n",
        "def has_hidden_element(soup):\n",
        "    for input in soup.find_all(\"input\"):\n",
        "        if input.get(\"type\") == \"hidden\":\n",
        "            return 1\n",
        "        else:\n",
        "            pass\n",
        "    return 0\n",
        "\n",
        "\n",
        "# has_audio\n",
        "def has_audio(soup):\n",
        "    if len(soup.find_all(\"audio\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has_video\n",
        "def has_video(soup):\n",
        "    if len(soup.find_all(\"video\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# number_of_inputs\n",
        "def number_of_inputs(soup):\n",
        "    return len(soup.find_all(\"input\"))\n",
        "\n",
        "\n",
        "# number_of_buttons\n",
        "def number_of_buttons(soup):\n",
        "    return len(soup.find_all(\"button\"))\n",
        "\n",
        "\n",
        "# number_of_images\n",
        "def number_of_images(soup):\n",
        "    image_tags = len(soup.find_all(\"image\"))\n",
        "    count = 0\n",
        "    for meta in soup.find_all(\"meta\"):\n",
        "        if meta.get(\"type\") or meta.get(\"name\") == \"image\":\n",
        "            count += 1\n",
        "    return image_tags + count\n",
        "\n",
        "\n",
        "# number_of_option\n",
        "def number_of_option(soup):\n",
        "    return len(soup.find_all(\"option\"))\n",
        "\n",
        "\n",
        "# number_of_list\n",
        "def number_of_list(soup):\n",
        "    return len(soup.find_all(\"li\"))\n",
        "\n",
        "\n",
        "# number_of_TH\n",
        "def number_of_TH(soup):\n",
        "    return len(soup.find_all(\"th\"))\n",
        "\n",
        "\n",
        "# number_of_TR\n",
        "def number_of_TR(soup):\n",
        "    return len(soup.find_all(\"tr\"))\n",
        "\n",
        "\n",
        "# number_of_href\n",
        "def number_of_href(soup):\n",
        "    count = 0\n",
        "    for link in soup.find_all(\"link\"):\n",
        "        if link.get(\"href\"):\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "\n",
        "# number_of_paragraph\n",
        "def number_of_paragraph(soup):\n",
        "    return len(soup.find_all(\"p\"))\n",
        "\n",
        "\n",
        "# number_of_script\n",
        "def number_of_script(soup):\n",
        "    return len(soup.find_all(\"script\"))\n",
        "\n",
        "\n",
        "# length_of_title\n",
        "def length_of_title(soup):\n",
        "    if soup.title == None:\n",
        "        return 0\n",
        "    return len(soup.title.text)\n",
        "\n",
        "# has h1\n",
        "def has_h1(soup):\n",
        "    if len(soup.find_all(\"h1\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has h2\n",
        "def has_h2(soup):\n",
        "    if len(soup.find_all(\"h2\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has h3\n",
        "def has_h3(soup):\n",
        "    if len(soup.find_all(\"h3\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# length of text\n",
        "def length_of_text(soup):\n",
        "    return len(soup.get_text())\n",
        "\n",
        "\n",
        "# number of clickable button\n",
        "def number_of_clickable_button(soup):\n",
        "    count = 0\n",
        "    for button in soup.find_all(\"button\"):\n",
        "        if button.get(\"type\") == \"button\":\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "\n",
        "# number of a\n",
        "def number_of_a(soup):\n",
        "    return len(soup.find_all(\"a\"))\n",
        "\n",
        "\n",
        "# number of img\n",
        "def number_of_img(soup):\n",
        "    return len(soup.find_all(\"img\"))\n",
        "\n",
        "\n",
        "# number of div class\n",
        "def number_of_div(soup):\n",
        "    return len(soup.find_all(\"div\"))\n",
        "\n",
        "\n",
        "# number of figures\n",
        "def number_of_figure(soup):\n",
        "    return len(soup.find_all(\"figure\"))\n",
        "\n",
        "\n",
        "# has footer\n",
        "def has_footer(soup):\n",
        "    if len(soup.find_all(\"footer\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has form\n",
        "def has_form(soup):\n",
        "    if len(soup.find_all(\"form\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has textarea\n",
        "def has_text_area(soup):\n",
        "    if len(soup.find_all(\"textarea\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has iframe\n",
        "def has_iframe(soup):\n",
        "    if len(soup.find_all(\"iframe\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has text input\n",
        "def has_text_input(soup):\n",
        "    for input in soup.find_all(\"input\"):\n",
        "        if input.get(\"type\") == \"text\":\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "# number of meta\n",
        "def number_of_meta(soup):\n",
        "    return len(soup.find_all(\"meta\"))\n",
        "\n",
        "\n",
        "# has nav\n",
        "def has_nav(soup):\n",
        "    if len(soup.find_all(\"nav\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has object\n",
        "def has_object(soup):\n",
        "    if len(soup.find_all(\"object\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# has picture\n",
        "def has_picture(soup):\n",
        "    if len(soup.find_all(\"picture\")) > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# number of sources\n",
        "def number_of_sources(soup):\n",
        "    return len(soup.find_all(\"source\"))\n",
        "\n",
        "\n",
        "# number of span\n",
        "def number_of_span(soup):\n",
        "    return len(soup.find_all(\"span\"))\n",
        "\n",
        "\n",
        "# number of table\n",
        "def number_of_table(soup):\n",
        "    return len(soup.find_all(\"table\"))\n",
        "\n",
        "#Checks for IP address in URL (Have_IP)\n",
        "def havingIP(url):\n",
        "  try:\n",
        "    ipaddress.ip_address(url)\n",
        "    ip = 1\n",
        "  except:\n",
        "    ip = 0\n",
        "  return ip\n",
        "\n",
        "#Checks the presence of @ in URL (Have_At)\n",
        "def haveAtSign(url):\n",
        "  if \"@\" in url:\n",
        "    at = 1\n",
        "  else:\n",
        "    at = 0\n",
        "  return at\n",
        "\n",
        "#Finding the length of URL and categorizing (URL_Length)\n",
        "def getLength(url):\n",
        "  if len(url) < 54:\n",
        "    length = 0\n",
        "  else:\n",
        "    length = 1\n",
        "  return length\n",
        "\n",
        "#Gives number of '/' in URL (URL_Depth)\n",
        "def getDepth(url):\n",
        "  s = urlparse(url).path.split('/')\n",
        "  depth = 0\n",
        "  for j in range(len(s)):\n",
        "    if len(s[j]) != 0:\n",
        "      depth = depth+1\n",
        "  return depth\n",
        "\n",
        "#Checking for redirection '//' in the url (Redirection)\n",
        "def redirection(url):\n",
        "  pos = url.rfind('//')\n",
        "  if pos > 6:\n",
        "    if pos > 7:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "#Existence of “HTTPS” Token in the Domain Part of the URL (https_Domain)\n",
        "def httpDomain(url):\n",
        "  domain = urlparse(url).netloc\n",
        "  if 'https' in domain:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "#listing shortening services\n",
        "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
        "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
        "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
        "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
        "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
        "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
        "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
        "                      r\"tr\\.im|link\\.zip\\.net\"\n",
        "\n",
        "#Checking for Shortening Services in URL (Tiny_URL)\n",
        "def tinyURL(url):\n",
        "    match=re.search(shortening_services,url)\n",
        "    if match:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "#Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n",
        "def prefixSuffix(url):\n",
        "    if '-' in urlparse(url).netloc:\n",
        "        return 1            # phishing\n",
        "    else:\n",
        "        return 0            # legitimate\n",
        "\n",
        "\n",
        "#DEFINE A FUNCTION THAT CREATES A VECTOR BY RUNNING ALL FEATURE FUNCTIONS FOR THE SOUP OBJECT\n",
        "def create_vector(soup, url):\n",
        "    features = [url]\n",
        "    features.extend([\n",
        "        has_title(soup),\n",
        "        has_input(soup),\n",
        "        has_button(soup),\n",
        "        has_image(soup),\n",
        "        has_submit(soup),\n",
        "        has_link(soup),\n",
        "        has_password(soup),\n",
        "        has_email_input(soup),\n",
        "        has_hidden_element(soup),\n",
        "        has_audio(soup),\n",
        "        has_video(soup),\n",
        "        number_of_inputs(soup),\n",
        "        number_of_buttons(soup),\n",
        "        number_of_images(soup),\n",
        "        number_of_option(soup),\n",
        "        number_of_list(soup),\n",
        "        number_of_TH(soup),\n",
        "        number_of_TR(soup),\n",
        "        number_of_href(soup),\n",
        "        number_of_paragraph(soup),\n",
        "        number_of_script(soup),\n",
        "        length_of_title(soup),\n",
        "        has_h1(soup),\n",
        "        has_h2(soup),\n",
        "        has_h3(soup),\n",
        "        length_of_text(soup),\n",
        "        number_of_clickable_button(soup),\n",
        "        number_of_a(soup),\n",
        "        number_of_img(soup),\n",
        "        number_of_div(soup),\n",
        "        number_of_figure(soup),\n",
        "        has_footer(soup),\n",
        "        has_form(soup),\n",
        "        has_text_area(soup),\n",
        "        has_iframe(soup),\n",
        "        has_text_input(soup),\n",
        "        number_of_meta(soup),\n",
        "        has_nav(soup),\n",
        "        has_object(soup),\n",
        "        has_picture(soup),\n",
        "        number_of_sources(soup),\n",
        "        number_of_span(soup),\n",
        "        number_of_table(soup),\n",
        "        havingIP(url),\n",
        "        haveAtSign(url),\n",
        "        getLength(url),\n",
        "        getDepth(url),\n",
        "        redirection(url),\n",
        "        httpDomain(url),\n",
        "        tinyURL(url),\n",
        "        prefixSuffix(url)\n",
        "    ])\n",
        "    return features\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a93334d6-90a9-45a9-a89d-13ac27cea35a",
      "metadata": {
        "id": "a93334d6-90a9-45a9-a89d-13ac27cea35a"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "disable_warnings(InsecureRequestWarning)\n",
        "\n",
        "# Step 1: csv to dataframe\n",
        "\"\"\"\n",
        "URL_file_name = \"verified_online.csv\" #Phishing\n",
        "data_frame = pd.read_csv(URL_file_name)\n",
        "\n",
        "# retrieve only \"url\" column and convert it to a list\n",
        "URL_list = data_frame['url'].to_list()\n",
        "\"\"\"\n",
        "#For Legitimate\n",
        "URL_file_name = \"tranco_58XXN.csv\"\n",
        "data_frame = pd.read_csv(URL_file_name, header=None)\n",
        "data_frame.head()\n",
        "URL_list = data_frame[1].to_list()\n",
        "\n",
        "# restrict the URL count\n",
        "begin = 4501\n",
        "end = 7000\n",
        "collection_list = URL_list[begin:end]\n",
        "\n",
        "# only for the legitimate\n",
        "#tag = \"http://\"\n",
        "#collection_list = [tag + url for url in collection_list]\n",
        "#collection_list = [\"http://\" + url if not url.startswith(('http://', 'https://')) else url for url in URL_list[begin:end]]\n",
        "\n",
        "# function to scrape the content of the URL and convert to a structured form for each\n",
        "\n",
        "import socket\n",
        "\n",
        "def clean_url(url):\n",
        "    try:\n",
        "        parsed = urlparse(url)\n",
        "        if not parsed.scheme:\n",
        "            url = 'http://' + url  # Default scheme to http if missing\n",
        "        cleaned_url = urlunparse(urlparse(url))  # Re-parse to clean\n",
        "        return cleaned_url\n",
        "    except Exception as e:\n",
        "        print(f\"Invalid URL {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Check DNS to ensure the domain can be resolved\n",
        "def check_dns(url):\n",
        "    try:\n",
        "        domain = urlparse(url).netloc\n",
        "        if not domain:\n",
        "            return False\n",
        "        socket.gethostbyname(domain)\n",
        "        return True\n",
        "    except socket.gaierror:\n",
        "        print(f\"DNS resolution failed for {url}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing URL {url}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Safe get request with exception handling\n",
        "def safe_get(url, timeout=4):\n",
        "    cleaned_url = clean_url(url)\n",
        "    if not cleaned_url:\n",
        "        return None\n",
        "    try:\n",
        "        response = requests.get(cleaned_url, verify=False, timeout=timeout)\n",
        "        response.raise_for_status()\n",
        "        return response\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching {cleaned_url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Main data collection function that processes a list of URLs\n",
        "def create_structured_data(url_list):\n",
        "    data_list = []\n",
        "    for i, url in enumerate(url_list):\n",
        "        cleaned_url = clean_url(url)\n",
        "        if not cleaned_url:\n",
        "            print(f\"Skipping invalid URL: {url}\")\n",
        "            continue\n",
        "        print(f\"Processing {i+1}/{len(url_list)}: {cleaned_url}\")\n",
        "        if check_dns(cleaned_url):\n",
        "            response = safe_get(cleaned_url)\n",
        "            if response and response.status_code == 200:\n",
        "                soup = BeautifulSoup(response.content, 'html.parser')\n",
        "                vector = create_vector(soup, cleaned_url)  # Ensure create_vector is correctly implemented\n",
        "                data_list.append(vector)\n",
        "                print(f\"Processed successfully: {cleaned_url}\")\n",
        "            else:\n",
        "                print(f\"Failed for {cleaned_url}, status code: {response.status_code if response else 'No response'}\")\n",
        "        else:\n",
        "            print(f\"DNS resolution failed for {cleaned_url}\")\n",
        "    return data_list\n",
        "\n",
        "\n",
        "data = create_structured_data(collection_list)\n",
        "\n",
        "columns = [\n",
        "    'URL',\n",
        "    'has_title',\n",
        "    'has_input',\n",
        "    'has_button',\n",
        "    'has_image',\n",
        "    'has_submit',\n",
        "    'has_link',\n",
        "    'has_password',\n",
        "    'has_email_input',\n",
        "    'has_hidden_element',\n",
        "    'has_audio',\n",
        "    'has_video',\n",
        "    'number_of_inputs',\n",
        "    'number_of_buttons',\n",
        "    'number_of_images',\n",
        "    'number_of_option',\n",
        "    'number_of_list',\n",
        "    'number_of_th',\n",
        "    'number_of_tr',\n",
        "    'number_of_href',\n",
        "    'number_of_paragraph',\n",
        "    'number_of_script',\n",
        "    'length_of_title',\n",
        "    'has_h1',\n",
        "    'has_h2',\n",
        "    'has_h3',\n",
        "    'length_of_text',\n",
        "    'number_of_clickable_button',\n",
        "    'number_of_a',\n",
        "    'number_of_img',\n",
        "    'number_of_div',\n",
        "    'number_of_figure',\n",
        "    'has_footer',\n",
        "    'has_form',\n",
        "    'has_text_area',\n",
        "    'has_iframe',\n",
        "    'has_text_input',\n",
        "    'number_of_meta',\n",
        "    'has_nav',\n",
        "    'has_object',\n",
        "    'has_picture',\n",
        "    'number_of_sources',\n",
        "    'number_of_span',\n",
        "    'number_of_table',\n",
        "    'Have_IP',\n",
        "    'Have_At',\n",
        "    'URL_Length',\n",
        "    'URL_Depth',\n",
        "    'Redirection',\n",
        "    'https_Domain',\n",
        "    'TinyURL',\n",
        "    'Prefix/Suffix'\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data=data, columns=columns)\n",
        "print(df)\n",
        "# labelling\n",
        "df['Phishing'] = 0\n",
        "\n",
        "df.to_csv(\"/content/structured_legitimate_data1.csv\", mode='a', index=False, header=False)  # header should be false after the first run\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
